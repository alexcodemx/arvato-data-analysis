{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: Create a Customer Segmentation Report for Arvato Financial Services\n",
    "\n",
    "In this project, you will analyze demographics data for customers of a mail-order sales company in Germany, comparing it against demographics information for the general population. You'll use unsupervised learning techniques to perform customer segmentation, identifying the parts of the population that best describe the core customer base of the company. Then, you'll apply what you've learned on a third dataset with demographics information for targets of a marketing campaign for the company, and use a model to predict which individuals are most likely to convert into becoming customers for the company. The data that you will use has been provided by our partners at Bertelsmann Arvato Analytics, and represents a real-life data science task.\n",
    "\n",
    "If you completed the first term of this program, you will be familiar with the first part of this project, from the unsupervised learning project. The versions of those two datasets used in this project will include many more features and has not been pre-cleaned. You are also free to choose whatever approach you'd like to analyzing the data rather than follow pre-determined steps. In your work on this project, make sure that you carefully document your steps and decisions, since your main deliverable for this project will be a blog post reporting your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump, load\n",
    "from scripts.preprocessing import data_preprocessing, principal_components\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Supervised Learning Model\n",
    "\n",
    "Now that you've found which parts of the population are more likely to be customers of the mail-order company, it's time to build a prediction model. Each of the rows in the \"MAILOUT\" data files represents an individual that was targeted for a mailout campaign. Ideally, we should be able to use the demographic information from each individual to decide whether or not it will be worth it to include that person in the campaign.\n",
    "\n",
    "The \"MAILOUT\" data has been split into two approximately equal parts, each with almost 43 000 data rows. In this part, you can verify your model with the \"TRAIN\" partition, which includes a column, \"RESPONSE\", that states whether or not a person became a customer of the company following the campaign. In the next part, you'll need to create predictions on the \"TEST\" partition, where the \"RESPONSE\" column has been withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LNR</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTER_KIND1</th>\n",
       "      <th>ALTER_KIND2</th>\n",
       "      <th>ALTER_KIND3</th>\n",
       "      <th>ALTER_KIND4</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1763</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1771</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1776</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1460</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1783</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42957</th>\n",
       "      <td>66338</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42958</th>\n",
       "      <td>67629</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42959</th>\n",
       "      <td>68273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42960</th>\n",
       "      <td>68581</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42961</th>\n",
       "      <td>69224</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42962 rows × 367 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LNR AGER_TYP AKT_DAT_KL ALTER_HH ALTER_KIND1 ALTER_KIND2 ALTER_KIND3  \\\n",
       "0       1763        2          1        8         NaN         NaN         NaN   \n",
       "1       1771        1          4       13         NaN         NaN         NaN   \n",
       "2       1776        1          1        9         NaN         NaN         NaN   \n",
       "3       1460        2          1        6         NaN         NaN         NaN   \n",
       "4       1783        2          1        9         NaN         NaN         NaN   \n",
       "...      ...      ...        ...      ...         ...         ...         ...   \n",
       "42957  66338        2          1        0         NaN         NaN         NaN   \n",
       "42958  67629       -1          1        0         NaN         NaN         NaN   \n",
       "42959  68273        1          1       16         NaN         NaN         NaN   \n",
       "42960  68581        2          1       18         NaN         NaN         NaN   \n",
       "42961  69224        2          1       13         NaN         NaN         NaN   \n",
       "\n",
       "      ALTER_KIND4 ALTERSKATEGORIE_FEIN ANZ_HAUSHALTE_AKTIV  ... VK_DHT4A  \\\n",
       "0             NaN                    8                  15  ...        5   \n",
       "1             NaN                   13                   1  ...        1   \n",
       "2             NaN                    7                   0  ...        6   \n",
       "3             NaN                    6                   4  ...        8   \n",
       "4             NaN                    9                  53  ...        2   \n",
       "...           ...                  ...                 ...  ...      ...   \n",
       "42957         NaN                   10                   1  ...        1   \n",
       "42958         NaN                   14                   1  ...        1   \n",
       "42959         NaN                   10                   2  ...        1   \n",
       "42960         NaN                   13                   3  ...        2   \n",
       "42961         NaN                    9                   3  ...        7   \n",
       "\n",
       "      VK_DISTANZ VK_ZG11 W_KEIT_KIND_HH WOHNDAUER_2008 WOHNLAGE ZABEOTYP  \\\n",
       "0              2       1              6              9        3        3   \n",
       "1              2       1              4              9        7        1   \n",
       "2              4       2            NaN              9        2        3   \n",
       "3             11      11              6              9        1        3   \n",
       "4              2       1              6              9        3        3   \n",
       "...          ...     ...            ...            ...      ...      ...   \n",
       "42957          1       1              4              8        7        1   \n",
       "42958          1       1              5              9        7        1   \n",
       "42959          2       1              2              9        7        1   \n",
       "42960          3       4              2              9        2        3   \n",
       "42961          7       4              6              9        7        3   \n",
       "\n",
       "      RESPONSE ANREDE_KZ ALTERSKATEGORIE_GROB  \n",
       "0            0         2                    4  \n",
       "1            0         2                    3  \n",
       "2            0         1                    4  \n",
       "3            0         2                    4  \n",
       "4            0         1                    3  \n",
       "...        ...       ...                  ...  \n",
       "42957        0         1                    4  \n",
       "42958        0         1                    3  \n",
       "42959        0         1                    4  \n",
       "42960        0         2                    4  \n",
       "42961        0         2                    4  \n",
       "\n",
       "[42962 rows x 367 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailout_train = pd.read_csv('../files/Udacity_MAILOUT_052018_TRAIN.csv', sep=';', dtype=object)\n",
    "mailout_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Dataframe Shape: (42962, 367)\n",
      "\n",
      "Succesfully removed 62 columns!\n",
      "BIP_FLAG was not found in the DF\n",
      "CAMEO_DEUINTL_2015 was not found in the DF\n",
      "D19_KK_KUNDENTYP was not found in the DF\n",
      "GEOSCORE_KLS7 was not found in the DF\n",
      "GEOSCORE_KLS7 was not found in the DF\n",
      "HAUSHALTSSTRUKTUR was not found in the DF\n",
      "HAUSHALTSSTRUKTUR was not found in the DF\n",
      "KBA13_CCM_1400_2500 was not found in the DF\n",
      "OST_WEST_KZ was not found in the DF\n",
      "SOHO_FLAG was not found in the DF\n",
      "WACHSTUMSGEBIET_NB was not found in the DF\n",
      "WACHSTUMSGEBIET_NB was not found in the DF\n",
      "The columns below threshold: ['TITEL_KZ'] were removed.\n",
      "Variance Explained by all 101 principal components:  0.7050989870534948\n"
     ]
    }
   ],
   "source": [
    "y = mailout_train['RESPONSE']\n",
    "\n",
    "# Preprocess data\n",
    "X = data_preprocessing(mailout_train)\n",
    "\n",
    "# Get Principal Components \n",
    "\n",
    "X, X_pca = principal_components(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('gb', GradientBoostingClassifier())],\n",
       " 'verbose': False,\n",
       " 'gb': GradientBoostingClassifier(),\n",
       " 'gb__ccp_alpha': 0.0,\n",
       " 'gb__criterion': 'friedman_mse',\n",
       " 'gb__init': None,\n",
       " 'gb__learning_rate': 0.1,\n",
       " 'gb__loss': 'deviance',\n",
       " 'gb__max_depth': 3,\n",
       " 'gb__max_features': None,\n",
       " 'gb__max_leaf_nodes': None,\n",
       " 'gb__min_impurity_decrease': 0.0,\n",
       " 'gb__min_impurity_split': None,\n",
       " 'gb__min_samples_leaf': 1,\n",
       " 'gb__min_samples_split': 2,\n",
       " 'gb__min_weight_fraction_leaf': 0.0,\n",
       " 'gb__n_estimators': 100,\n",
       " 'gb__n_iter_no_change': None,\n",
       " 'gb__presort': 'deprecated',\n",
       " 'gb__random_state': None,\n",
       " 'gb__subsample': 1.0,\n",
       " 'gb__tol': 0.0001,\n",
       " 'gb__validation_fraction': 0.1,\n",
       " 'gb__verbose': 0,\n",
       " 'gb__warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('gb', GradientBoostingClassifier())])\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 839.2019877433777 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "parameters = {\n",
    "    'gb__max_depth': range(3,5),\n",
    "    'gb__random_state': [42]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gb__max_depth': 3, 'gb__random_state': 42} \n",
      "\n",
      "Pipeline(steps=[('gb', GradientBoostingClassifier(random_state=42))]) \n",
      "\n",
      "0.9806489498296964\n",
      "0.9827902383975173\n",
      "0.5031935641053371\n"
     ]
    }
   ],
   "source": [
    "print(cv.best_params_,'\\n')\n",
    "print(cv.best_estimator_,'\\n')\n",
    "print(cv.best_score_)\n",
    "\n",
    "best_model = cv.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     13999\n",
      "           1       0.03      0.01      0.02       179\n",
      "\n",
      "    accuracy                           0.98     14178\n",
      "   macro avg       0.51      0.50      0.50     14178\n",
      "weighted avg       0.98      0.98      0.98     14178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('rf', RandomForestClassifier())],\n",
       " 'verbose': False,\n",
       " 'rf': RandomForestClassifier(),\n",
       " 'rf__bootstrap': True,\n",
       " 'rf__ccp_alpha': 0.0,\n",
       " 'rf__class_weight': None,\n",
       " 'rf__criterion': 'gini',\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 'auto',\n",
       " 'rf__max_leaf_nodes': None,\n",
       " 'rf__max_samples': None,\n",
       " 'rf__min_impurity_decrease': 0.0,\n",
       " 'rf__min_impurity_split': None,\n",
       " 'rf__min_samples_leaf': 1,\n",
       " 'rf__min_samples_split': 2,\n",
       " 'rf__min_weight_fraction_leaf': 0.0,\n",
       " 'rf__n_estimators': 100,\n",
       " 'rf__n_jobs': None,\n",
       " 'rf__oob_score': False,\n",
       " 'rf__random_state': None,\n",
       " 'rf__verbose': 0,\n",
       " 'rf__warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('rf', RandomForestClassifier())])\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 774.8248388767242 seconds ---\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "#    'rf__max_depth':range(2,6),\n",
    "    'rf__min_samples_leaf': [1, 2],\n",
    "    'rf__min_samples_split': [2, 5],\n",
    "    'rf__n_estimators': [100]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__min_samples_leaf': 2, 'rf__min_samples_split': 2, 'rf__n_estimators': 100} \n",
      "\n",
      "Pipeline(steps=[('rf', RandomForestClassifier(min_samples_leaf=2))]) \n",
      "\n",
      "0.9877362459189485\n",
      "0.9873748060375229\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(cv.best_params_,'\\n')\n",
    "print(cv.best_estimator_,'\\n')\n",
    "print(cv.best_score_)\n",
    "\n",
    "best_model = cv.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     13999\n",
      "           1       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.99     14178\n",
      "   macro avg       0.49      0.50      0.50     14178\n",
      "weighted avg       0.97      0.99      0.98     14178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('ab', AdaBoostClassifier())],\n",
       " 'verbose': False,\n",
       " 'ab': AdaBoostClassifier(),\n",
       " 'ab__algorithm': 'SAMME.R',\n",
       " 'ab__base_estimator': None,\n",
       " 'ab__learning_rate': 1.0,\n",
       " 'ab__n_estimators': 50,\n",
       " 'ab__random_state': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([('ab', AdaBoostClassifier())])\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 263.304753780365 seconds ---\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'ab__n_estimators': [50,60,70],\n",
    "    'ab__random_state': [42]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ab__n_estimators': 50, 'ab__random_state': 42} \n",
      "\n",
      "Pipeline(steps=[('ab', AdaBoostClassifier(random_state=42))]) \n",
      "\n",
      "0.9877015056028113\n",
      "0.9873748060375229\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(cv.best_params_,'\\n')\n",
    "print(cv.best_estimator_,'\\n')\n",
    "print(cv.best_score_)\n",
    "\n",
    "best_model = cv.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro/.pyenv/versions/3.8.2/envs/general-python/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     13999\n",
      "           1       0.00      0.00      0.00       179\n",
      "\n",
      "    accuracy                           0.99     14178\n",
      "   macro avg       0.49      0.50      0.50     14178\n",
      "weighted avg       0.97      0.99      0.98     14178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "dump(model, 'model.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Kaggle Competition\n",
    "\n",
    "Now that you've created a model to predict which individuals are most likely to respond to a mailout campaign, it's time to test that model in competition through Kaggle. If you click on the link [here](http://www.kaggle.com/t/21e6d45d4c574c7fa2d868f0e8c83140), you'll be taken to the competition page where, if you have a Kaggle account, you can enter. If you're one of the top performers, you may have the chance to be contacted by a hiring manager from Arvato or Bertelsmann for an interview!\n",
    "\n",
    "Your entry to the competition should be a CSV file with two columns. The first column should be a copy of \"LNR\", which acts as an ID number for each individual in the \"TEST\" partition. The second column, \"RESPONSE\", should be some measure of how likely each individual became a customer – this might not be a straightforward probability. As you should have found in Part 2, there is a large output class imbalance, where most individuals did not respond to the mailout. Thus, predicting individual classes and using accuracy does not seem to be an appropriate performance evaluation method. Instead, the competition will be using AUC to evaluate performance. The exact values of the \"RESPONSE\" column do not matter as much: only that the higher values try to capture as many of the actual customers as possible, early in the ROC curve sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = load('model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro/.pyenv/versions/3.8.2/envs/general-python/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "mailout_test = pd.read_csv('../files/Udacity_MAILOUT_052018_TEST.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Dataframe Shape: (42833, 366)\n",
      "\n",
      "Succesfully removed 61 columns!\n",
      "BIP_FLAG was not found in the DF\n",
      "CAMEO_DEUINTL_2015 was not found in the DF\n",
      "D19_KK_KUNDENTYP was not found in the DF\n",
      "GEOSCORE_KLS7 was not found in the DF\n",
      "GEOSCORE_KLS7 was not found in the DF\n",
      "HAUSHALTSSTRUKTUR was not found in the DF\n",
      "HAUSHALTSSTRUKTUR was not found in the DF\n",
      "KBA13_CCM_1400_2500 was not found in the DF\n",
      "OST_WEST_KZ was not found in the DF\n",
      "SOHO_FLAG was not found in the DF\n",
      "WACHSTUMSGEBIET_NB was not found in the DF\n",
      "WACHSTUMSGEBIET_NB was not found in the DF\n",
      "The columns below threshold: ['TITEL_KZ'] were removed.\n",
      "Variance Explained by all 101 principal components:  0.7046784203442937\n"
     ]
    }
   ],
   "source": [
    "X = data_preprocessing(mailout_test)\n",
    "X, X_pca = principal_components(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_kaggle = pd.DataFrame()\n",
    "final_kaggle['LNR'] = mailout_test['LNR']\n",
    "final_kaggle['RESPONSE'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_kaggle.to_csv(\"final_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
